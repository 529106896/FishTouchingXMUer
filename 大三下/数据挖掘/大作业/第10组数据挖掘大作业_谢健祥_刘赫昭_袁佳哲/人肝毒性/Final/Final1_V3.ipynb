{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 人肝毒性数据集V3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预备工作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1)导入需要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as  pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import decomposition\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn           as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import tree\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2)加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_V1 = r'V1_ECFP4.csv'\n",
    "path_V2 = r'V2_ECFP4.csv'\n",
    "path_V3 = r'V3_ECFP4.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_x</th>\n",
       "      <th>1_x</th>\n",
       "      <th>2_x</th>\n",
       "      <th>3_x</th>\n",
       "      <th>4_x</th>\n",
       "      <th>5_x</th>\n",
       "      <th>6_x</th>\n",
       "      <th>7_x</th>\n",
       "      <th>8_x</th>\n",
       "      <th>9_x</th>\n",
       "      <th>...</th>\n",
       "      <th>1027_y</th>\n",
       "      <th>57804</th>\n",
       "      <th>8061</th>\n",
       "      <th>10962</th>\n",
       "      <th>10153</th>\n",
       "      <th>5566</th>\n",
       "      <th>2597</th>\n",
       "      <th>874_y</th>\n",
       "      <th>57149</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02115</td>\n",
       "      <td>0.03211</td>\n",
       "      <td>-0.02618</td>\n",
       "      <td>0.00932</td>\n",
       "      <td>0.01491</td>\n",
       "      <td>0.00428</td>\n",
       "      <td>0.01452</td>\n",
       "      <td>-0.00260</td>\n",
       "      <td>-0.00472</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01372</td>\n",
       "      <td>-0.01007</td>\n",
       "      <td>0.00708</td>\n",
       "      <td>-0.00790</td>\n",
       "      <td>-0.01119</td>\n",
       "      <td>0.01697</td>\n",
       "      <td>-0.00627</td>\n",
       "      <td>-0.00721</td>\n",
       "      <td>0.00690</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01936</td>\n",
       "      <td>0.01332</td>\n",
       "      <td>0.03463</td>\n",
       "      <td>-0.00217</td>\n",
       "      <td>-0.01188</td>\n",
       "      <td>0.00317</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.01888</td>\n",
       "      <td>-0.00600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.08093</td>\n",
       "      <td>-0.00731</td>\n",
       "      <td>-0.06143</td>\n",
       "      <td>-0.00253</td>\n",
       "      <td>-0.04999</td>\n",
       "      <td>0.01730</td>\n",
       "      <td>0.00477</td>\n",
       "      <td>-0.00133</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01924</td>\n",
       "      <td>-0.01487</td>\n",
       "      <td>0.01042</td>\n",
       "      <td>0.01155</td>\n",
       "      <td>-0.04849</td>\n",
       "      <td>-0.00483</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00921</td>\n",
       "      <td>0.01372</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_x  1_x  2_x  3_x  4_x  5_x  6_x  7_x  8_x  9_x  ...   1027_y    57804  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0  ... -0.02115  0.03211   \n",
       "1    0    0    0    0    0    0    0    0    0    0  ... -0.01372 -0.01007   \n",
       "2    0    0    0    0    0    0    0    0    0    0  ... -0.01936  0.01332   \n",
       "3    0    1    0    0    0    1    0    0    0    0  ... -0.08093 -0.00731   \n",
       "4    0    0    0    0    0    0    0    0    0    0  ...  0.01924 -0.01487   \n",
       "\n",
       "      8061    10962    10153     5566     2597    874_y    57149  label  \n",
       "0 -0.02618  0.00932  0.01491  0.00428  0.01452 -0.00260 -0.00472      1  \n",
       "1  0.00708 -0.00790 -0.01119  0.01697 -0.00627 -0.00721  0.00690      1  \n",
       "2  0.03463 -0.00217 -0.01188  0.00317  0.00000 -0.01888 -0.00600      1  \n",
       "3 -0.06143 -0.00253 -0.04999  0.01730  0.00477 -0.00133  0.00200      1  \n",
       "4  0.01042  0.01155 -0.04849 -0.00483  0.00000 -0.00921  0.01372      1  \n",
       "\n",
       "[5 rows x 3227 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_csv(path_V3)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = raw_df['label']\n",
    "label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照说明文件中的描述，把数据的不同属性分开，其中ECFP4为离散型数据，其余为连续型数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252, 3226)\n",
      "(252, 2048)\n",
      "(252, 200)\n",
      "(252, 978)\n",
      "(252, 2248)\n"
     ]
    }
   ],
   "source": [
    "X=raw_df.iloc[:,:-1]\n",
    "ECFP4 = raw_df.iloc[:,0:2048]\n",
    "phychem = raw_df.iloc[:,2048:2248]\n",
    "L7 = raw_df.iloc[:,2248:-1]\n",
    "phychem_ECFP4 = pd.concat([phychem,ECFP4],axis=1)\n",
    "print(X.shape)\n",
    "print(ECFP4.shape)\n",
    "print(phychem.shape)\n",
    "print(L7.shape)\n",
    "print(phychem_ECFP4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3)函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入分类器，获取评价标准，如accuracy、precision等\n",
    "def my_cross_validate_score(estimator,X,y,cv = 5,mean = False,ret_est=False):\n",
    "    kf = model_selection.StratifiedKFold(n_splits=cv)\n",
    "    #存储k次训练中得到的模型与其对应的分数\n",
    "    res = dict()\n",
    "    accuracy = []\n",
    "    f1_score = []\n",
    "    auc = []\n",
    "    recall_0 = []\n",
    "    recall_1 = []\n",
    "    precision_0 = []\n",
    "    precision_1 = []\n",
    "    it=1\n",
    "    #进行k次训练\n",
    "    for train_index, test_index in kf.split(X,y):\n",
    "        # print('train_index', train_index, 'test_index', test_index)\n",
    "        train_X, train_y = X.iloc[train_index],y.iloc[train_index]\n",
    "        test_X, test_y = X.iloc[test_index],y.iloc[test_index]\n",
    "        estimator.fit(train_X,train_y)\n",
    "        clf_predict = estimator.predict(test_X)\n",
    "        report = metrics.classification_report(test_y,clf_predict,output_dict=True)\n",
    "        \n",
    "        accuracy.append(report['accuracy'])\n",
    "        f1_score.append(report['macro avg']['f1-score'])\n",
    "        try:\n",
    "            if isinstance(estimator, SVC) or isinstance(estimator, LinearSVC):\n",
    "                score = estimator.decision_function(test_X)\n",
    "                test_y_hot = label_binarize(test_y, classes=(0, 1))\n",
    "                fpr, tpr, thresholds = metrics.roc_curve(test_y_hot.ravel(), score.ravel())\n",
    "                auc.append(metrics.auc(fpr, tpr))\n",
    "            else:\n",
    "                auc.append(metrics.roc_auc_score(test_y,estimator.predict_proba(test_X)[:,1]))\n",
    "        except:\n",
    "            auc.append(0)\n",
    "        recall_0.append(report['0']['recall'])\n",
    "        recall_1.append(report['1']['recall'])\n",
    "        precision_0.append(report['0']['precision'])\n",
    "        precision_1.append(report['1']['precision'])\n",
    "        # print(\"iteration\",it,\".....\")\n",
    "        it+=1\n",
    "        res['accuracy'] = accuracy\n",
    "        res['f1_score'] = f1_score\n",
    "        res['auc'] = auc\n",
    "        res['recall_0'] = recall_0\n",
    "        res['recall_1'] = recall_1\n",
    "        res['precision_0'] = precision_0\n",
    "        res['precision_1'] = precision_1\n",
    "        \n",
    "    if mean:\n",
    "        for key in res.keys():\n",
    "            res[key] = np.mean(res[key])\n",
    "    if ret_est:\n",
    "        return res,estimator\n",
    "    else:\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_heatmap(cm,col_names,figsize=(5, 5)):\n",
    "    f, ax = plt.subplots(figsize=figsize)\n",
    "    ax =  sns.heatmap(cm,cmap=\"YlGnBu_r\",fmt=\"d\",annot=True,ax=ax,xticklabels=col_names,yticklabels=col_names)\n",
    "    ax.set_xlabel(\"cluster\")\n",
    "    ax.set_ylabel(\"truth\")\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_state = 2022528"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4)模型构建的一些前置工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "als = [DecisionTreeClassifier(),RandomForestClassifier(),ExtraTreeClassifier(),GradientBoostingClassifier()\n",
    ",xgb.XGBClassifier(probability=True,use_label_encoder=False),SVC(),LinearSVC(),KNeighborsClassifier()]\n",
    "names = ['DecisionTreeClassifier','RandomForestClassifier','ExtraTreeClassifier',\n",
    "'GradientBoostingClassifier','XGBClassifier','SVC','LinearSVC','KNeighborsClassifier']\n",
    "\n",
    "for clf,name in zip(als,names):\n",
    "    res = my_cross_validate_score(clf,ECFP4,label,mean=True,cv=10)\n",
    "    print(name)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_up_sampler():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def up_sample(self,X_train,y_train):\n",
    "        index_1 = y_train[y_train == 1].index\n",
    "        index_0 = y_train[y_train == 0].index\n",
    "        X_train_0 = X_train.loc[index_0]\n",
    "        y_train_0 = y_train.loc[index_0]\n",
    "        scale = len(index_1)/len(index_0)\n",
    "        # print('scale:',scale)\n",
    "        ret_X = copy.deepcopy(X_train)\n",
    "        ret_y = copy.deepcopy(y_train)\n",
    "        for i in range(math.ceil(scale)-1):\n",
    "            ret_X = ret_X.append(X_train_0)\n",
    "            ret_y = ret_y.append(y_train_0)\n",
    "        return ret_X,ret_y  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_vote_select_with_up_sample_clf():\n",
    "    def __init__(self, topN,score = 'recall',offset = 0):\n",
    "        #使用phychem进行训练的基分类器\n",
    "        #KNN不支持特征选择\n",
    "        GDBT_phychem = GradientBoostingClassifier()\n",
    "        RandomForest_phychem = RandomForestClassifier()\n",
    "        XGB_phychem = xgb.XGBClassifier(verbosity=0,use_label_encoder=False)\n",
    "        SVC_phychem = SVC(kernel=\"linear\")\n",
    "        # KNN_phychem = KNeighborsClassifier()\n",
    "        #使用ECFP4_phychem进行训练的基分类器\n",
    "        RandomForest_ECFP4_phychem = RandomForestClassifier()\n",
    "        ExtraTree_ECFP4_phychem = ExtraTreeClassifier()\n",
    "        SVC_ECFP4_phychem = SVC(kernel=\"linear\")\n",
    "        LinearSVC_ECFP4_phychem = LinearSVC()\n",
    "        # KNN_ECFP4_phychem = KNeighborsClassifier()\n",
    "        #使用ECFP4进行训练的基分类器\n",
    "        RandomForest_ECFP4 = RandomForestClassifier()\n",
    "        GDBT_ECFP4 = GradientBoostingClassifier()\n",
    "        SVC_ECFP4 = SVC(kernel=\"linear\")\n",
    "        LinearSVC_ECFP4 = LinearSVC()\n",
    "        # KNN_ECFP4 = KNeighborsClassifier()\n",
    "        \n",
    "        self.base_als_phychem = [GDBT_phychem,RandomForest_phychem,XGB_phychem,SVC_phychem]\n",
    "        self.base_als_ECFP4_phychem = [RandomForest_ECFP4_phychem,ExtraTree_ECFP4_phychem,SVC_ECFP4_phychem,LinearSVC_ECFP4_phychem]\n",
    "        self.base_als_ECFP4 = [RandomForest_ECFP4,GDBT_ECFP4,SVC_ECFP4,LinearSVC_ECFP4]\n",
    "        self.all_base_algo = self.base_als_phychem+self.base_als_ECFP4_phychem+self.base_als_ECFP4\n",
    "        self.algo_names = ['GDBT_phychem','RandomForest_phychem','XGB_phychem','SVC_phychem',\n",
    "        'RandomForest_ECFP4_phychem','ExtraTree_ECFP4_phychem','SVC_ECFP4_phychem','LinearSVC_ECFP4_phychem',\n",
    "        'RandomForest_ECFP4','GDBT_ECFP4','SVC_ECFP4','LinearSVC_ECFP4']\n",
    "        selectors = []\n",
    "        for algo in self.all_base_algo:\n",
    "            selectors.append(SelectFromModel(estimator = algo))\n",
    "        self.algo_selector_set = list(zip(self.all_base_algo,selectors,self.algo_names))\n",
    "\n",
    "        self.res_dic = dict()\n",
    "        self.keys = ['accuracy','f1_score','auc','recall_0','recall_1','precision_0','precision_1']\n",
    "\n",
    "        self.kmeans = KMeans(n_clusters=2)\n",
    "        # self.prepredictor = My_pre_clus()\n",
    "        self.topN = topN\n",
    "        self.score = score\n",
    "        self.offset = offset\n",
    "\n",
    "    def res_map(self,x):\n",
    "        thres = int(self.topN/2)+self.offset\n",
    "        # print(thres)\n",
    "        if x<=thres:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "    def fit(self,X_train,y_train):\n",
    "        my_up_sampler = My_up_sampler()\n",
    "        # print('X_train.shape',X_train.shape)\n",
    "        # print('y_train.shape',y_train.shape)\n",
    "        X,y = my_up_sampler.up_sample(X_train,y_train)\n",
    "        # print(X.shape)\n",
    "        # print(y.shape)\n",
    "        ECFP4 = X.iloc[:,0:1684]\n",
    "        phychem = X.iloc[:,1684:1860]\n",
    "        L7 = X.iloc[:,1860:]\n",
    "        phychem_ECFP4 = pd.concat([phychem,ECFP4],axis=1)\n",
    "\n",
    "        for key in self.keys:\n",
    "            self.res_dic[key] = []\n",
    "\n",
    "        for i in range(len(self.algo_selector_set)):\n",
    "            t=self.algo_selector_set[i]\n",
    "            # print('fitting:',t[2])\n",
    "            if i in range(4):\n",
    "                t[1].fit(phychem,y)\n",
    "                train_selected = t[1].transform(phychem)\n",
    "            elif i in range(4,8):\n",
    "                t[1].fit(phychem_ECFP4,y)\n",
    "                train_selected = t[1].transform(phychem_ECFP4)\n",
    "            else:\n",
    "                t[1].fit(ECFP4,y)\n",
    "                train_selected = t[1].transform(ECFP4)\n",
    "            \n",
    "            train_selected = pd.DataFrame(train_selected)\n",
    "            temp_res = my_cross_validate_score(t[0],train_selected,y,cv=10,mean=True)\n",
    "            for key in self.keys:\n",
    "                self.res_dic[key].append(temp_res[key])\n",
    "\n",
    "        pca_2=decomposition.PCA(n_components=2)\n",
    "        phychem_2d = pca_2.fit_transform(phychem)\n",
    "        self.kmeans.fit(phychem_2d)\n",
    "        # self.prepredictor.fit(X_train,y_train)\n",
    "\n",
    "        # print(self.res_dic)\n",
    "    def predict(self,X_test):\n",
    "        ECFP4 = X_test.iloc[:,0:1684]\n",
    "        phychem = X_test.iloc[:,1684:1860]\n",
    "        L7 = X_test.iloc[:,1860:]\n",
    "        phychem_ECFP4 = pd.concat([phychem,ECFP4],axis=1)\n",
    "        \n",
    "        if self.score in ['recall','precision']:\n",
    "            clf41_index = pd.DataFrame(self.res_dic).sort_values([self.score+'_1'],ascending=False)[:self.topN].index\n",
    "            clf40_index = pd.DataFrame(self.res_dic).sort_values([self.score+'_0'],ascending=False)[:self.topN].index\n",
    "        else:\n",
    "            clf41_index = pd.DataFrame(self.res_dic).sort_values([self.score],ascending=False)[:self.topN].index\n",
    "            clf40_index = pd.DataFrame(self.res_dic).sort_values([self.score],ascending=False)[:self.topN].index \n",
    "\n",
    "\n",
    "        clf41 = []\n",
    "        clf40 = []\n",
    "        for i,j in zip(clf41_index,clf40_index):\n",
    "            clf41.append(copy.deepcopy(self.algo_selector_set[i]))\n",
    "            clf40.append(copy.deepcopy(self.algo_selector_set[j]))\n",
    "        \n",
    "        pca_2=decomposition.PCA(n_components=2)\n",
    "        phychem_2d = pca_2.fit_transform(phychem)\n",
    "        prepred = self.kmeans.predict(phychem_2d)\n",
    "        # prepred = self.prepredictor.predict(X_test)\n",
    "        clf41_preds = []\n",
    "        clf40_preds = []\n",
    "\n",
    "        for i in range(len(clf41)):\n",
    "            t = clf41[i]\n",
    "            if clf41_index[i] in range(0,4):\n",
    "                test_data = phychem\n",
    "            elif clf41_index[i] in range(4,8):\n",
    "                test_data = phychem_ECFP4\n",
    "            else:\n",
    "                test_data = ECFP4\n",
    "            clf41_preds.append(t[0].predict(t[1].transform(test_data)))\n",
    "\n",
    "        for i in range(len(clf40)):\n",
    "            t = clf40[i]\n",
    "            if clf40_index[i] in range(0,4):\n",
    "                test_data = phychem\n",
    "            elif clf40_index[i] in range(4,8):\n",
    "                test_data = phychem_ECFP4\n",
    "            else:\n",
    "                test_data = ECFP4\n",
    "            clf40_preds.append(t[0].predict(t[1].transform(test_data)))\n",
    "\n",
    "        # col_names = ['clf0','clf1','clf2','clf3','clf4']\n",
    "        clf41_preds_dic = dict()\n",
    "        clf40_preds_dic = dict()\n",
    "        \n",
    "        for i  in range(self.topN):\n",
    "            key = 'clf'+str(i)\n",
    "            clf41_preds_dic[key] = clf41_preds[i]\n",
    "            clf40_preds_dic[key] = clf40_preds[i]\n",
    "        \n",
    "        clf41_preds_df = pd.DataFrame(clf41_preds_dic)\n",
    "        clf40_preds_df = pd.DataFrame(clf40_preds_dic)\n",
    "\n",
    "        clf41_voted_pred = clf41_preds_df.sum(axis=1).map(self.res_map)\n",
    "        clf40_voted_pred = clf40_preds_df.sum(axis=1).map(self.res_map)\n",
    "        \n",
    "        res = []\n",
    "\n",
    "        for i in range(len(prepred)):\n",
    "            if prepred[i] == 1:\n",
    "                res.append(clf41_voted_pred[i])\n",
    "            else:\n",
    "                res.append(clf40_voted_pred[i])\n",
    "\n",
    "        # print('prepred',prepred)\n",
    "        # print('clf41',clf41)\n",
    "        # print('clf40',clf40)\n",
    "        # print('clf41_preds_dic',clf41_preds_dic)\n",
    "        # print('clf40_preds_dic',clf40_preds_dic)\n",
    "        # print('clf41_voted_pred',clf41_voted_pred)\n",
    "        # print('clf40_voted_pred',clf40_voted_pred)\n",
    "        return res        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done accuracy-1\n",
      "Done accuracy-3\n",
      "Done accuracy-5\n",
      "Done precision-1\n",
      "Done precision-3\n",
      "Done precision-5\n",
      "Done recall-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done recall-3\n",
      "Done recall-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done f1_score-1\n",
      "Done f1_score-3\n",
      "Done f1_score-5\n",
      "accuracy-1\n",
      "{'accuracy': 0.6466153846153846, 'f1_score': 0.5345747930009426, 'auc': 0.0, 'recall_0': 0.30476190476190473, 'recall_1': 0.7713450292397661, 'precision_0': 0.3246428571428571, 'precision_1': 0.7527157465857156}\n",
      "accuracy-3\n",
      "{'accuracy': 0.6349230769230768, 'f1_score': 0.5250185063265558, 'auc': 0.0, 'recall_0': 0.30476190476190473, 'recall_1': 0.7555555555555556, 'precision_0': 0.29797619047619045, 'precision_1': 0.7496535456287778}\n",
      "accuracy-5\n",
      "{'accuracy': 0.6467692307692307, 'f1_score': 0.5325242026635214, 'auc': 0.0, 'recall_0': 0.29047619047619044, 'recall_1': 0.7766081871345029, 'precision_0': 0.32662698412698415, 'precision_1': 0.7489340385276918}\n",
      "precision-1\n",
      "{'accuracy': 0.6429230769230767, 'f1_score': 0.5263546660418735, 'auc': 0.0, 'recall_0': 0.3047619047619047, 'recall_1': 0.7660818713450293, 'precision_0': 0.3004906204906205, 'precision_1': 0.7525994520615263}\n",
      "precision-3\n",
      "{'accuracy': 0.6429230769230768, 'f1_score': 0.5243336470890649, 'auc': 0.0, 'recall_0': 0.28809523809523807, 'recall_1': 0.7713450292397661, 'precision_0': 0.3333333333333333, 'precision_1': 0.7491295373984834}\n",
      "precision-5\n",
      "{'accuracy': 0.6469230769230769, 'f1_score': 0.5176035068822767, 'auc': 0.0, 'recall_0': 0.2595238095238095, 'recall_1': 0.7874269005847953, 'precision_0': 0.305, 'precision_1': 0.744857598541809}\n",
      "recall-1\n",
      "{'accuracy': 0.6541538461538461, 'f1_score': 0.5370020873738064, 'auc': 0.0, 'recall_0': 0.28809523809523807, 'recall_1': 0.7871345029239765, 'precision_0': 0.4194949494949495, 'precision_1': 0.7499913568506246}\n",
      "recall-3\n",
      "{'accuracy': 0.6547692307692308, 'f1_score': 0.5321280100503086, 'auc': 0.0, 'recall_0': 0.28809523809523807, 'recall_1': 0.7883040935672514, 'precision_0': 0.3158333333333333, 'precision_1': 0.7538093897846221}\n",
      "recall-5\n",
      "{'accuracy': 0.6544615384615384, 'f1_score': 0.5343151165014602, 'auc': 0.0, 'recall_0': 0.28809523809523807, 'recall_1': 0.7871345029239765, 'precision_0': 0.3419047619047618, 'precision_1': 0.7519602035391509}\n",
      "f1_score-1\n",
      "{'accuracy': 0.6466153846153846, 'f1_score': 0.5345747930009426, 'auc': 0.0, 'recall_0': 0.30476190476190473, 'recall_1': 0.7713450292397661, 'precision_0': 0.3246428571428571, 'precision_1': 0.7527157465857156}\n",
      "f1_score-3\n",
      "{'accuracy': 0.6429230769230768, 'f1_score': 0.5359834186072575, 'auc': 0.0, 'recall_0': 0.3214285714285714, 'recall_1': 0.7608187134502924, 'precision_0': 0.3146428571428571, 'precision_1': 0.7549167035235147}\n",
      "f1_score-5\n",
      "{'accuracy': 0.6509230769230768, 'f1_score': 0.5351478071292313, 'auc': 0.0, 'recall_0': 0.29047619047619044, 'recall_1': 0.7821637426900584, 'precision_0': 0.3299603174603175, 'precision_1': 0.7501997026880928}\n"
     ]
    }
   ],
   "source": [
    "scores = ['accuracy','precision','recall','f1_score']\n",
    "topNs = range(1,6,2)\n",
    "reports = []\n",
    "\n",
    "for score in scores :\n",
    "    for topN in topNs:\n",
    "        reports.append(\"{}-{}\".format(score,topN))\n",
    "        my_vote_clf = My_vote_select_with_up_sample_clf(topN,score=score)\n",
    "        report = my_cross_validate_score(my_vote_clf,X,label,cv = 10,mean=True)\n",
    "        #reports.append(metrics.classification_report(y_test,my_vote_clf_pred))\n",
    "        reports.append(report)\n",
    "        print(\"Done {}-{}\".format(score,topN))\n",
    "for report in reports:\n",
    "    print(report)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7758e92e9a61d7a3490898707f7eeb937c85e9d1e8d4e877cc6c187218f226d5"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
